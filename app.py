import re
import json
import yaml
import streamlit as st

from extract_job import parse_job, Job
from extract_candidate import Candidate, parse_candidate
from rank import rank
from build_embeddings import build as rebuild_embeddings


# ============================
# SMALL STYLES
# ============================
STYLES = """
<style>
.chip{padding:4px 10px;border-radius:8px;margin:2px;display:inline-block;font-size:13px}
.chip-ok{background:#1f4f2f;color:#00ff9d}
.chip-part{background:#2b2b2b;color:#ffd95a}
.chip-miss{background:#4a1111;color:#ff6b6b}
.card{border:1px solid #444;padding:15px;border-radius:10px;background:#141414;margin-bottom:15px}
.pre{background:#111;border:1px solid #333;border-radius:8px;padding:12px;white-space:pre-wrap;overflow-x:auto}
</style>
"""
st.markdown(STYLES, unsafe_allow_html=True)


# ============================
# CONFIG & HELPERS
# ============================
with open("data/config.yaml", "r", encoding="utf-8") as f:
    CONFIG = yaml.safe_load(f) or {}

def norm(text: str):
    return text.strip().lower().replace(".", "").replace("-", " ").replace("_", " ")

def normalize_skill(skill: str):
    if not skill:
        return None
    s = norm(skill)
    s = re.sub(r"[^\w\+\./# ]+", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    aliases = CONFIG.get("aliases", {}).get("skills", {})
    return aliases.get(s, s)

def explode_skills(lst):
    out = []
    for x in (lst or []):
        if not x: continue
        x = re.sub(r"[\(\)]", "", x)
        parts = re.split(r"[,/&\+\|]| –∏ | and | or | –∏–ª–∏ ", x, flags=re.IGNORECASE)
        for p in parts:
            p = p.strip()
            if p and len(p.split()) <= 4:
                out.append(normalize_skill(p))
    return out

def dedup(seq):
    seen, res = set(), []
    for s in seq:
        if s and s not in seen:
            seen.add(s); res.append(s)
    return res

def uniq_pairs(pairs):
    """
    –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é (req), –æ—Å—Ç–∞–≤–ª—è–µ–º —Å–∞–º—ã–π —Å–∏–ª—å–Ω—ã–π –º–∞—Ç—á.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ (req, found, sim) –±–µ–∑ –¥—É–±–ª–µ–π req.
    """
    best = {}
    for req, found, sim in pairs:
        if not req: continue
        key = req.lower()
        if (key not in best) or (sim > best[key][1]):
            best[key] = (req, found, sim)
    # —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –≤—ã–≤–æ–¥
    return [best[k] for k in sorted(best.keys())]

def pct(x):
    try: return f"{float(x)*100:.0f}%"
    except: return "‚Äî"

def pct1(x):
    try: return f"{float(x)*100:.1f}%"
    except: return "‚Äî"

def year_word(y: float):
    y = int(y)
    if y % 10 == 1 and y % 100 != 11: return "–≥–æ–¥"
    if 2 <= y % 10 <= 4 and not (12 <= y % 100 <= 14): return "–≥–æ–¥–∞"
    return "–ª–µ—Ç"


# ============================
# LOAD
# ============================
def load_data():
    with open("data/jobs.json", "r", encoding="utf-8") as f:
        jobs = [Job.model_validate(x) for x in json.load(f)]
    with open("data/candidates.json", "r", encoding="utf-8") as f:
        candidates = [Candidate.model_validate(x) for x in json.load(f)]
    return jobs, candidates


st.set_page_config(page_title="ML –ü–æ–¥–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", layout="wide")
st.title("üöÄ AI-–ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –ø–æ–¥–±–æ—Ä–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤")

jobs, candidates = load_data()
job_list = {j.id: j.title for j in jobs}


# ============================
# SIDEBAR ‚Äî –º—è–≥–∫–∏–µ –¥–µ—Ñ–æ–ª—Ç—ã
# ============================
st.sidebar.header("‚öô –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è")
vector_w = st.sidebar.slider("üß† –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–ª–∏–∑–æ—Å—Ç—å", 0.0, 1.0, 0.40)
skill_w  = st.sidebar.slider("üõ† –ù–∞–≤—ã–∫-–º–∞—Ç—á–∏–Ω–≥ (–≤–µ—Å.)", 0.0, 1.0, 0.30)
exp_w    = st.sidebar.slider("üìÖ –û–ø—ã—Ç", 0.0, 1.0, 0.15)
domain_w = st.sidebar.slider("üè¢ –î–æ–º–µ–Ω", 0.0, 1.0, 0.10)
level_w  = st.sidebar.slider("üéñ –£—Ä–æ–≤–µ–Ω—å", 0.0, 1.0, 0.05)

top_k = st.sidebar.slider("–ü–æ–∫–∞–∑–∞—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", 1, 15, 5)

st.sidebar.header("üß© –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤")
strict_thr  = st.sidebar.slider("–°—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥", 0.50, 0.95, 0.75, 0.01)
partial_thr = st.sidebar.slider("–ß–∞—Å—Ç–∏—á–Ω—ã–π –ø–æ—Ä–æ–≥", 0.30, 0.90, 0.55, 0.01)
nice_weight = st.sidebar.slider("–í–µ—Å nice-to-have", 0.0, 1.0, 0.25, 0.05)

threshold = st.sidebar.slider("üîé –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π Score", 0.0, 1.0, 0.0, 0.01)

if st.sidebar.button("üîÑ –û–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"):
    jobs, candidates = load_data()
    job_list = {j.id: j.title for j in jobs}
    st.sidebar.success("‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ!")


# ============================
# TABS
# ============================
tab_find, tab_all_cand, tab_all_jobs, tab_add, tab_add_job = st.tabs([
    "üîç –ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤",
    "üìã –í—Å–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã",
    "üìå –í—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏",
    "‚ûï –î–æ–±–∞–≤–∏—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞",
    "üÜï –î–æ–±–∞–≤–∏—Ç—å –≤–∞–∫–∞–Ω—Å–∏—é"
])


# =========================================================
# TAB 1 - –ü–û–ò–°–ö
# =========================================================
with tab_find:
    st.subheader("üìå –í—ã–±–µ—Ä–∏—Ç–µ –≤–∞–∫–∞–Ω—Å–∏—é")

    job_id = st.selectbox("–í–∞–∫–∞–Ω—Å–∏–∏:", options=list(job_list.keys()), format_func=lambda x: job_list[x])
    job = next(j for j in jobs if j.id == job_id)

    with st.expander("üìÑ –ü–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ", expanded=True):
        st.markdown(f"### **{job.title}** ‚Äî {job.level_required}")
        st.write(f"**–î–æ–º–µ–Ω:** {job.domain or '‚Äî'}")
        st.write(f"**–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è:** {job.specialization or '‚Äî'}")
        st.write(f"**–°—Ç–µ–∫:** {', '.join(job.stack or [])}")
        st.write(f"**–§—Ä–µ–π–º–≤–æ—Ä–∫–∏:** {', '.join(job.substack or [])}")

        if getattr(job, "exp_min_years_overall", None):
            y = job.exp_min_years_overall
            st.write(f"**–û–ø—ã—Ç:** –æ—Ç {int(y)} {year_word(y)}")
        elif getattr(job, "exp_min_years_by_area", None):
            st.write("**–û–ø—ã—Ç –ø–æ –æ–±–ª–∞—Å—Ç—è–º:**")
            for area, years in job.exp_min_years_by_area.items():
                st.write(f"‚Ä¢ {area}: –æ—Ç {int(years)} {year_word(years)}")
        else:
            st.write("**–û–ø—ã—Ç:** –Ω–µ —É–∫–∞–∑–∞–Ω")

        st.write(f"**Must-have:** ‚úÖ {', '.join(job.must_have or [])}")
        if job.nice_to_have:
            st.write(f"**Nice-to-have:** ‚≠ê {', '.join(job.nice_to_have)}")

        if job.salary_max:
            st.success(f"üí∞ –ë—é–¥–∂–µ—Ç: –¥–æ {job.salary_max}")

        with st.expander("üßæ –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞—è–≤–∫–∏"):
            st.code(job.source_text, language=None)

    if st.button("üî• –ù–∞–π—Ç–∏ –ª—É—á—à–∏—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤"):
        st.write("‚è≥ –ü–æ–¥–±–æ—Ä...")

        results = rank(
            job_id,
            top_n=top_k,
            custom_weights=dict(
                vector=vector_w, skills=skill_w, experience=exp_w, domain=domain_w, level=level_w
            ),
            threshold=threshold,
            strict_thr=strict_thr,
            partial_thr=partial_thr,
            nice_weight=nice_weight
        )

        if not results:
            st.warning("‚ùó –ù–∏–∫—Ç–æ –Ω–µ –ø—Ä–æ—à—ë–ª –ø–æ—Ä–æ–≥")
        else:
            st.success("‚úÖ –õ—É—á—à–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã:")

            # –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏
            req_full = dedup(explode_skills((job.must_have or []) + (job.nice_to_have or []) + (job.stack or []) + (job.substack or [])))
            must_req = dedup(explode_skills(job.must_have or []))
            nice_req = dedup(explode_skills(job.nice_to_have or []))

            for r in results:
                cand = next(c for c in candidates if c.id == r["candidate_id"])

                score = float(r["final_score"])
                st.markdown(f"<div class='card'><h3 style='margin:0;'>üßë {r['name']} ‚Äî Score: <b>{score:.3f}</b> ({pct1(score)})</h3></div>", unsafe_allow_html=True)

                # –º–µ—Ç—Ä–∏–∫–∏
                cols = st.columns(5)
                cols[0].metric("üß† –°–µ–º–∞–Ω—Ç–∏–∫–∞", pct(r["vector_similarity"]))
                cols[1].metric("üõ† –ù–∞–≤—ã–∫–∏ (–≤–µ—Å.)", pct(r["skill_coverage"]))
                cols[2].metric("üß© –ù–∞–≤—ã–∫–∏ (—É–Ω–∏–∫.)", pct(len(set([m[0].lower() for m in r.get("skill_matches", [])] + [p[0].lower() for p in r.get("skill_partials", [])])) / len(req_full) if req_full else 1))
                cols[3].metric("üìÖ –û–ø—ã—Ç", pct(r["experience_score"]))
                cols[4].metric("üè¢ –î–æ–º–µ–Ω", "‚úÖ" if r["domain_match"] else "‚ùå")

                # —á–∏—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏ –±–µ–∑ –¥—É–±–ª–µ–π
                strict_pairs = uniq_pairs(r.get("skill_matches", []))
                part_pairs   = uniq_pairs(r.get("skill_partials", []))

                strict_terms  = [req for (req, _found, _sim) in strict_pairs]
                partial_terms = [req for (req, _found, _sim) in part_pairs]
                covered_lower = set([s.lower() for s in strict_terms + partial_terms])

                # –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—á–∏—Ç–∞–µ–º –ø–æ req_full, —É–±–∏—Ä–∞–µ–º –ø–æ–∫—Ä—ã—Ç—ã–µ
                missing_must  = [s for s in must_req if s.lower() not in covered_lower]
                # "–ø—Ä–æ—á–∏–µ" = –≤—Å—ë req_full –º–∏–Ω—É—Å must, –∏ —Ç–æ–∂–µ –º–∏–Ω—É—Å –ø–æ–∫—Ä—ã—Ç—ã–µ
                other_req = [s for s in req_full if s not in set(must_req) | set(nice_req)]
                missing_other = [s for s in other_req if s.lower() not in covered_lower]

                # –∫–∞—Ä—Ç–æ—á–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                with st.expander("üß© –°–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –Ω–∞–≤—ã–∫–∞–º"):
                    if strict_pairs:
                        st.markdown("**‚úÖ –°—Ç—Ä–æ–≥–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç:**")
                        chips = " ".join(
                            f"<span class='chip chip-ok'>{req} ‚ûù {found}</span>"
                            for (req, found, _sim) in strict_pairs
                        )
                        st.markdown(chips, unsafe_allow_html=True)
                    if part_pairs:
                        st.markdown("**üî∂ –ß–∞—Å—Ç–∏—á–Ω–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç:**")
                        chips = " ".join(
                            f"<span class='chip chip-part'>{req} ‚âà {found}</span>"
                            for (req, found, _sim) in part_pairs
                        )
                        st.markdown(chips, unsafe_allow_html=True)
                    if missing_must:
                        st.markdown("**‚ùå –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö:**")
                        chips = " ".join(f"<span class='chip chip-miss'>{m}</span>" for m in sorted(set(missing_must)))
                        st.markdown(chips, unsafe_allow_html=True)
                    if missing_other:
                        st.markdown("**‚≠ê –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ, –Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç:**")
                        chips = " ".join(f"<span class='chip'>{m}</span>" for m in sorted(set(missing_other)))
                        st.markdown(chips, unsafe_allow_html=True)

                # –ø–æ–¥—Å–≤–µ—Ç–∫–∞ –≤ —Ä–µ–∑—é–º–µ (—Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã)
                with st.expander("‚ú® –ü–æ–¥—Å–≤–µ—Ç–∫–∞ –≤ —Ä–µ–∑—é–º–µ"):
                    highlight_terms = dedup(strict_terms + partial_terms + missing_must + missing_other)
                    text = cand.source_text

                    if highlight_terms:
                        safe_terms = [re.escape(x) for x in highlight_terms if x]
                        if safe_terms:
                            pattern = r"(" + "|".join(safe_terms) + r")"
                            strict_set  = set(s.lower() for s in strict_terms)
                            partial_set = set(s.lower() for s in partial_terms)
                            miss_must_set  = set(s.lower() for s in missing_must)

                            def recolor(mo):
                                tok = mo.group(0)
                                w = tok.lower()
                                if w in strict_set:
                                    return f"<span style='background:#003b1f;color:#00ff9d;padding:2px 5px;border-radius:6px;'>{tok}</span>"
                                if w in partial_set:
                                    return f"<span style='background:#2b2b2b;color:#ffd95a;padding:2px 5px;border-radius:6px;'>{tok}</span>"
                                if w in miss_must_set:
                                    return f"<span style='background:#4a1111;color:#ff6b6b;padding:2px 5px;border-radius:6px;'>{tok}</span>"
                                return f"<span style='background:#222;color:#bfbfbf;padding:2px 5px;border-radius:6px;'>{tok}</span>"

                            text = re.sub(pattern, recolor, text, flags=re.IGNORECASE)

                    st.markdown(f"<div class='pre'>{text}</div>", unsafe_allow_html=True)

                st.markdown("---")

    else:
        st.info("‚¨Ö –í—ã–±–µ—Ä–∏—Ç–µ –≤–∞–∫–∞–Ω—Å–∏—é –∏ –Ω–∞–∂–º–∏—Ç–µ '–ù–∞–π—Ç–∏'")


# =========================================================
# TAB 2 ‚Äì –í–°–ï –ö–ê–ù–î–ò–î–ê–¢–´
# =========================================================
with tab_all_cand:
    st.subheader("üìã –í—Å–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã")
    for c in candidates:
        st.markdown(
            f"""
            <div class="card" style="margin-bottom:12px;">
                <h4 style="margin:0;">üßë {c.name}</h4>
                <b>–£—Ä–æ–≤–µ–Ω—å:</b> {c.level or '‚Äî'}<br>
                <b>–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è:</b> {c.specialization or '‚Äî'}<br>
                <b>–ù–∞–≤—ã–∫–∏:</b> {', '.join(dedup(c.skills or []))}<br>
                <b>–§—Ä–µ–π–º–≤–æ—Ä–∫–∏:</b> {', '.join(dedup(c.subskills or []))}<br>
            </div>
            """,
            unsafe_allow_html=True,
        )
        with st.expander("üìÑ –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ"):
            st.markdown(f"<div class='pre'>{c.source_text}</div>", unsafe_allow_html=True)


# =========================================================
# TAB 3 ‚Äì –í–°–ï –í–ê–ö–ê–ù–°–ò–ò
# =========================================================
with tab_all_jobs:
    st.subheader("üìå –í—Å–µ –≤–∞–∫–∞–Ω—Å–∏–∏")
    for j in jobs:
        st.markdown(
            f"""
            <div class="card" style="background:linear-gradient(145deg,#161616,#111);margin-bottom:18px;">
                <h4 style="margin:0 0 10px;">üíº {j.title}</h4>
                <b>–£—Ä–æ–≤–µ–Ω—å:</b> {j.level_required or '‚Äî'}<br>
                <b>–î–æ–º–µ–Ω:</b> {j.domain or '‚Äî'}<br>
                <b>–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è:</b> {j.specialization or '‚Äî'}<br>
                <b>–°—Ç–µ–∫:</b> {', '.join(dedup(j.stack or [])) or '‚Äî'}<br>
                <b>Must:</b> {', '.join(dedup(j.must_have or [])) or '‚Äî'}<br>
                <b>Nice:</b> {', '.join(dedup(j.nice_to_have or [])) or '‚Äî'}<br>
            </div>
            """,
            unsafe_allow_html=True,
        )


# =========================================================
# TAB 4 ‚Äî –î–û–ë–ê–í–ò–¢–¨ –ö–ê–ù–î–ò–î–ê–¢–ê
# =========================================================
with tab_add:
    st.subheader("‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞")

    resume_text = st.text_area(
        "–í—Å—Ç–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞:",
        placeholder="–°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Å—é–¥–∞ —Ä–µ–∑—é–º–µ –ª—é–±–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞...",
        height=200
    )

    if st.button("‚úÖ –î–æ–±–∞–≤–∏—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞"):
        if not resume_text.strip():
            st.error("‚ùå –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç. –í—Å—Ç–∞–≤—å—Ç–µ —Ä–µ–∑—é–º–µ.")
        else:
            try:
                new_cand = parse_candidate(resume_text)

                st.markdown("<div class='card'><b>üìä –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞:</b></div>", unsafe_allow_html=True)

                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**üìÑ –ò—Å—Ö–æ–¥–Ω–æ–µ —Ä–µ–∑—é–º–µ:**")
                    st.markdown(f"<div class='pre'>{resume_text}</div>", unsafe_allow_html=True)
                with col2:
                    st.markdown("**‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ:**")
                    pretty = []
                    pretty.append(f"–ò–º—è: {new_cand.name or '‚Äî'}")
                    pretty.append(f"–£—Ä–æ–≤–µ–Ω—å: {new_cand.level or '‚Äî'}")
                    pretty.append(f"–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {new_cand.specialization or '‚Äî'}")
                    pretty.append(f"–õ–æ–∫–∞—Ü–∏—è: {new_cand.location or '‚Äî'}\n")
                    if new_cand.skills:
                        pretty.append(f"–ù–∞–≤—ã–∫–∏: {', '.join(dedup(new_cand.skills))}")
                    if new_cand.subskills:
                        pretty.append(f"–§—Ä–µ–π–º–≤–æ—Ä–∫–∏: {', '.join(dedup(new_cand.subskills))}")
                    if new_cand.years_by_area:
                        pretty.append("\n–û–ø—ã—Ç –ø–æ –æ–±–ª–∞—Å—Ç—è–º:")
                        for area, years in new_cand.years_by_area.items():
                            pretty.append(f"  ‚Ä¢ {area}: {int(years) if years==int(years) else years} –ª–µ—Ç")
                    if new_cand.salary_expectation:
                        pretty.append(f"\n–û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç–∞–≤–∫–∞: {new_cand.salary_expectation}")
                    st.markdown(f"<div class='pre'>{chr(10).join(pretty)}</div>", unsafe_allow_html=True)

                st.divider()

                with open("data/candidates.json", "r", encoding="utf-8") as f:
                    data = json.load(f)

                new_id = max(int(item["id"]) for item in data) + 1
                new_cand.id = new_id

                data.append(new_cand.model_dump())
                with open("data/candidates.json", "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)

                rebuild_embeddings()
                st.success(f"‚úÖ –ö–∞–Ω–¥–∏–¥–∞—Ç –¥–æ–±–∞–≤–ª–µ–Ω! ID = {new_id}")
                st.info("–î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã ‚Äî –º–æ–∂–Ω–æ –∏—Å–∫–∞—Ç—å —Å—Ä–µ–¥–∏ –Ω–æ–≤—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.")

            except Exception as e:
                st.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞")
                st.exception(e)


# =========================================================
# TAB 5 ‚Äî –î–û–ë–ê–í–ò–¢–¨ –í–ê–ö–ê–ù–°–ò–Æ
# =========================================================
with tab_add_job:
    st.subheader("üÜï –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –≤–∞–∫–∞–Ω—Å—Å–∏–∏")

    job_text = st.text_area(
        "–í—Å—Ç–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –∑–∞—è–≤–∫–∏:",
        placeholder="–í—Å—Ç–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ —Å–≤–æ–±–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ...",
        height=220
    )

    if st.button("‚úÖ –î–æ–±–∞–≤–∏—Ç—å –≤–∞–∫–∞–Ω—Å–∏—é"):
        if not job_text.strip():
            st.error("‚ùå –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç. –í—Å—Ç–∞–≤—å—Ç–µ –≤–∞–∫–∞–Ω—Å–∏—é.")
        else:
            try:
                new_job = parse_job(job_text)

                st.markdown("<div class='card'><b>üìä –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏:</b></div>", unsafe_allow_html=True)

                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**üìÑ –ò—Å—Ö–æ–¥–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ:**")
                    st.markdown(f"<div class='pre'>{job_text}</div>", unsafe_allow_html=True)
                with col2:
                    st.markdown("**‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ:**")
                    pretty = []
                    pretty.append(f"–ù–∞–∑–≤–∞–Ω–∏–µ: {new_job.title or '‚Äî'}")
                    pretty.append(f"–£—Ä–æ–≤–µ–Ω—å: {new_job.level_required or '‚Äî'}")
                    pretty.append(f"–î–æ–º–µ–Ω: {new_job.domain or '‚Äî'}")
                    pretty.append(f"–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {new_job.specialization or '‚Äî'}\n")
                    if new_job.stack:
                        pretty.append(f"–°—Ç–µ–∫: {', '.join(dedup(new_job.stack))}")
                    if new_job.substack:
                        pretty.append(f"–§—Ä–µ–π–º–≤–æ—Ä–∫–∏: {', '.join(dedup(new_job.substack))}")
                    if new_job.must_have:
                        pretty.append(f"–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏: {', '.join(dedup(new_job.must_have))}")
                    if new_job.nice_to_have:
                        pretty.append(f"–ñ–µ–ª–∞—Ç–µ–ª—å–Ω–æ: {', '.join(dedup(new_job.nice_to_have))}")
                    if new_job.salary_max:
                        pretty.append(f"–ë—é–¥–∂–µ—Ç: –¥–æ {new_job.salary_max}")
                    if getattr(new_job, "exp_min_years_overall", None):
                        y = int(new_job.exp_min_years_overall)
                        pretty.append(f"–û–ø—ã—Ç: –æ—Ç {y} –ª–µ—Ç")
                    if getattr(new_job, "exp_min_years_by_area", None):
                        pretty.append("–û–ø—ã—Ç –ø–æ –æ–±–ª–∞—Å—Ç—è–º:")
                        for area, years in new_job.exp_min_years_by_area.items():
                            pretty.append(f"  ‚Ä¢ {area}: –æ—Ç {int(years)} –ª–µ—Ç")
                    st.markdown(f"<div class='pre'>{chr(10).join(pretty)}</div>", unsafe_allow_html=True)

                st.divider()

                with open("data/jobs.json", "r", encoding="utf-8") as f:
                    data = json.load(f)

                new_id = max(int(item["id"]) for item in data) + 1
                new_job.id = new_id

                data.append(new_job.model_dump())
                with open("data/jobs.json", "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=2)

                st.success(f"‚úÖ –í–∞–∫–∞–Ω—Å–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∞! ID = {new_id}")
                st.info("–¢–µ–ø–µ—Ä—å –æ–Ω–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ –ø–æ–∏—Å–∫–µ.")

            except Exception as e:
                st.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏")
                st.exception(e)
